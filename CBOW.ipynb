{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('clos_clean.txt') as f:\\n    text = f.read()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "\"\"\"dataset_folder_path = 'data'\n",
    "dataset_filename = 'text8.zip'\n",
    "dataset_name = 'Text8 Dataset'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve(\n",
    "            'http://mattmahoney.net/dc/text8.zip',\n",
    "            dataset_filename,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\"\"\"\n",
    "        \n",
    "\"\"\"with open('clos_clean.txt') as f:\n",
    "    text = f.read()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Be able to articulate the difference between d...\n",
      "1      Demonstrate an understanding of scientific met...\n",
      "2      Interpret evidence from an experiment and how ...\n",
      "3      Critically read, evaluate claims made by both ...\n",
      "4      Distinguish differences between science and ot...\n",
      "5      Apply scepticism, the scientific method, evide...\n",
      "6      correctly recall the applicable data type to s...\n",
      "7      correctly write basic programming constructs: ...\n",
      "8      correctly perform calls to a function includin...\n",
      "9      correctly recall the use of basic data structu...\n",
      "10     given a moderately complex problem, use the ab...\n",
      "11     Given a problem, correctly choose a suitable d...\n",
      "12     given a tree, correctly apply breadth first an...\n",
      "13     correctly employ LIFO and/or FIFO structures t...\n",
      "14     correctly employ graphs to model applicable pr...\n",
      "15     write working programs to correctly solve prob...\n",
      "16     utilize debugging tools in order to debug prog...\n",
      "17     given an algorithm, analyze its computational ...\n",
      "18     identify and implement divide-and-conquer algo...\n",
      "19     plan and implement a programming project of mo...\n",
      "20     Be able to understand logic and logical argume...\n",
      "21     Be able to read and write simple mathematical ...\n",
      "22     Know combinatorics and will be able to apply c...\n",
      "23     Gain knowledge about graphs and some graph alg...\n",
      "24     Read papers/books and watch videos about histo...\n",
      "25     Have a knowledge of important research centers...\n",
      "26     Have an idea of the history of computing hardware\n",
      "27       Have an idea of the history of software systems\n",
      "28     Have an idea of the history of open source mov...\n",
      "29     Have an idea of some of the important personal...\n",
      "                             ...                        \n",
      "115    To utilize the architecture of Zynq device for...\n",
      "116    To develop and simulate digital design modules...\n",
      "117    To utilize Verilog HDL for designing modules a...\n",
      "118    To learn to develop embedded software applicat...\n",
      "119     Determine state-space representation for systems\n",
      "120    Determine the stability, controllability, and ...\n",
      "121    Design compensators using state-feedback, pole...\n",
      "122    learn the difference between RISC and CISC, Mo...\n",
      "123    understand the role of ISA in modern processor...\n",
      "124    understand how binary arithmetic is performed ...\n",
      "125    understand the organization of a single cycle ...\n",
      "126    understand the workings of caches and their ef...\n",
      "127    Extend the Reimann Sums argument to slicing vo...\n",
      "128    Represent motion in a plane using parametric e...\n",
      "129    Find areas and arc lengths of curves represent...\n",
      "130    Predict and explain linear transformations and...\n",
      "131    Explain and evaluate whether a given space is ...\n",
      "132    Predict and critique on the response and stabi...\n",
      "133    Use modern tools e.g. Python, Octave, MATLAB, ...\n",
      "134    Transform a description of random experiment i...\n",
      "135    Apply the axioms of probability and compute pr...\n",
      "136    Analyze a random experiment for presence of de...\n",
      "137    Construct discrete and continuous probability ...\n",
      "138    Compute moments and probabilities of events fr...\n",
      "139    Identify the preliminary aspects of thermodyna...\n",
      "140    Comprehend the 4 laws of thermodynamics, their...\n",
      "141    Apply the concepts of path dependence | indepe...\n",
      "142    Determine the ideal cycle analysis and apply t...\n",
      "143    Model the functioning of various heat engines,...\n",
      "144    Determine the procedure of calculating the mac...\n",
      "Name: Text, Length: 145, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../CLOS.csv\")\n",
    "print(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sentence for sentence in df['Text'] if sentence.count(' ') >= 2]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "nb_samples = sum(len(s) for s in corpus)\n",
    "V = len(tokenizer.word_index) + 1\n",
    "dim = 100\n",
    "window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(corpus, window_size, V):\n",
    "    maxlen = window_size*2\n",
    "    for words in corpus:\n",
    "        L = len(words)\n",
    "        for index, word in enumerate(words):\n",
    "            contexts = []\n",
    "            labels   = []            \n",
    "            s = index - window_size\n",
    "            e = index + window_size + 1\n",
    "            \n",
    "            contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
    "            labels.append(word)\n",
    "\n",
    "            x = sequence.pad_sequences(contexts, maxlen=maxlen)\n",
    "            y = np_utils.to_categorical(labels, V)\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow = Sequential()\n",
    "cbow.add(Embedding(input_dim=V, output_dim=dim, input_length=window_size*2))\n",
    "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(dim,)))\n",
    "cbow.add(Dense(V, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cbow.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12025.620184659958\n",
      "1 11368.931551933289\n",
      "2 11161.525293588638\n",
      "3 11091.765606880188\n",
      "4 11051.3975263834\n",
      "5 11003.50007045269\n",
      "6 10958.66885304451\n",
      "7 10910.168879806995\n",
      "8 10852.820275485516\n",
      "9 10787.426206409931\n"
     ]
    }
   ],
   "source": [
    "for ite in range(10):\n",
    "    loss = 0.\n",
    "    for x, y in generate_data(corpus, window_size, V):\n",
    "        loss += cbow.train_on_batch(x, y)\n",
    "\n",
    "    print(ite, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f = open('vectors.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(V-1, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = cbow.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    str_vec = ' '.join(map(str, list(vectors[i, :])))\n",
    "    f.write('{} {}\\n'.format(word, str_vec))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.5963079929351807),\n",
       " ('an', 0.5930779576301575),\n",
       " ('random', 0.5675033926963806),\n",
       " ('understanding', 0.5253812670707703),\n",
       " ('circuits', 0.5224876999855042),\n",
       " ('systems', 0.4931008517742157),\n",
       " ('such', 0.47586336731910706),\n",
       " ('have', 0.47550955414772034),\n",
       " ('electronics', 0.4716382622718811),\n",
       " ('experiment', 0.4682241380214691)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w2v.most_similar(positive=['knowledge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
